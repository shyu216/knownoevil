import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,e as a,o as n}from"./app-BndUADpl.js";const r={};function s(o,e){return n(),i("div",null,[...e[0]||(e[0]=[a(`<p>以下内容由这个数据库的readme.txt文件翻译而来。</p><h2 id="简介" tabindex="-1"><a class="header-anchor" href="#简介"><span>简介</span></a></h2><p>dPPG PFT 数据集由布里斯托大学计算机科学系视觉信息实验室发布，包含 35 名受试者在进行用力肺活量（FVC）和缓慢肺活量（SVC）肺功能测试时的体表深度信息。数据集共计 300 个 PFT 序列，并包含每个序列的肺量计（spirometer）数据作为验证基准。</p><ul><li>适用于：深度视觉、呼吸监测、医学信号处理等研究</li><li>采集方式：双 Kinect 深度相机（前后各一），同步采集</li><li>公开时间：2018 年 2 月</li><li>主要联系人：<a href="https://github.com/BristolVisualPFT" target="_blank" rel="noopener noreferrer">Vahid Soleimani</a></li><li>数据集主页：<a href="https://data.bris.ac.uk/data/dataset/1tqzx39mzkw832msuvy3obktqi" target="_blank" rel="noopener noreferrer">A Dataset for Depth-Based Whole Body Photoplethysmography in Remote Pulmonary Function Testing</a></li></ul><h2 id="数据集结构" tabindex="-1"><a class="header-anchor" href="#数据集结构"><span>数据集结构</span></a></h2><p>dPPG_dataset/<br> ├── subject_01/<br> │ ├── 1/<br> │ │ ├── calibration_params/<br> │ │ ├── data_bKinect/<br> │ │ ├── data_fKinect/<br> │ │ ├── intraKinect_synchronisation/<br> │ │ ├── results/<br> │ │ └── spirometer/<br> │ ├── 2/<br> │ └── ...<br> ├── subject_02/<br> │ ├── 10/<br> │ └── ...<br> ├── ...<br> ├── subject_PFT_index.txt<br> ├── subjects_meta.txt<br> ├── Data_Acquisition_guidance.pdf<br> └── blank_consent_form.pdf</p><h3 id="每个-pft-序列包含" tabindex="-1"><a class="header-anchor" href="#每个-pft-序列包含"><span>每个 PFT 序列包含：</span></a></h3><ul><li><strong>calibration_params/</strong>：Kinect 标定参数（焦距、主点、旋转/平移矩阵）</li><li><strong>data_bKinect/</strong>、<strong>data_fKinect/</strong>：后/前 Kinect 深度帧（PNG）、骨骼数据、元数据</li><li><strong>intraKinect_synchronisation/</strong>：同步信息</li><li><strong>results/</strong>：三篇论文的实验结果（详见下文）</li><li><strong>spirometer/</strong>：肺量计测量数据（体积-时间、流量-时间、PFT 指标）</li></ul><h2 id="评价指标" tabindex="-1"><a class="header-anchor" href="#评价指标"><span>评价指标</span></a></h2><ul><li><strong>NL2</strong>：归一化 L2 误差</li><li><strong>FRD</strong>：Fréchet 距离</li><li><strong>DTW</strong>：动态时间规整距离</li><li><strong>R²</strong>：决定系数</li></ul><h2 id="论文与引用" tabindex="-1"><a class="header-anchor" href="#论文与引用"><span>论文与引用</span></a></h2><p>如在研究中使用本数据集，请引用：</p><blockquote><p>V. Soleimani, M. Mirmehdi, D. Damen, M. Camplani, S. Hannuna, C. Sharp, J. Dodd.<br> &quot;Depth-based Whole Body Photoplethysmography in Remote Pulmonary Function Testing&quot;.<br> IEEE Transactions on Biomedical Engineering (TBME). <a href="http://ieeexplore.ieee.org/document/8186188/" target="_blank" rel="noopener noreferrer">论文链接</a></p></blockquote><h3 id="相关论文" tabindex="-1"><a class="header-anchor" href="#相关论文"><span>相关论文</span></a></h3><ul><li>[1] TBME: Depth-based Whole Body Photoplethysmography in Remote Pulmonary Function Testing</li><li>[2] ICIP 2018: Markerless Active Trunk Shape Modelling for Motion Tolerant Remote Respiratory Assessment</li><li>[3] ICPR 2018: Respiratory Motion Artifact Correction in Vision-based Lung Function Assessment</li><li>[4] 3DV 2016: 3D Data Acquisition and Registration using Two Opposing Kinects (<a href="https://github.com/BristolVisualPFT/3D_Data_Acquisition_Registration_Using_Kinects" target="_blank" rel="noopener noreferrer">源码</a>)</li></ul><h2 id="如何从前后-kinect-png-深度帧恢复-3d-点云" tabindex="-1"><a class="header-anchor" href="#如何从前后-kinect-png-深度帧恢复-3d-点云"><span>如何从前后 Kinect PNG 深度帧恢复 3D 点云</span></a></h2><ol><li><p><strong>读取深度帧</strong>：</p><ul><li>使用如 OpenCV、PIL 等库读取 PNG 格式的深度图像。</li><li>每个像素值代表该点的深度（单位通常为毫米）。</li></ul></li><li><p><strong>像素坐标转相机坐标</strong>：</p><ul><li>利用相机内参（焦距 Fx, Fy，主点 Px, Py）将像素 (u, v) 和深度 d 转换为相机坐标 (X, Y, Z)：<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>X = (u - Px) * d / Fx</span></span>
<span class="line"><span>Y = (v - Py) * d / Fy</span></span>
<span class="line"><span>Z = d</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li><li><p><strong>后 Kinect 点云配准到前 Kinect</strong>：</p><ul><li>使用 calibration_params 文件中的旋转矩阵 R 和平移向量 T，将后 Kinect 点云变换到前 Kinect 坐标系：<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>[Xf, Yf, Zf]^T = R * [Xb, Yb, Zb]^T + T</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li>其中 [Xb, Yb, Zb] 为后 Kinect 点云坐标，[Xf, Yf, Zf] 为配准后的坐标。</li></ul></li><li><p><strong>合并点云</strong>：</p><ul><li>将前后 Kinect 的点云合并，获得完整的 3D 体表点云。</li></ul></li></ol><blockquote><p>详细实现可参考 <a href="https://github.com/BristolVisualPFT/3D_Data_Acquisition_Registration_Using_Kinects" target="_blank" rel="noopener noreferrer">官方开源代码</a></p></blockquote>`,18)])])}const c=t(r,[["render",s]]),d=JSON.parse(`{"path":"/study/mscs/research/cv/rrmonitor/dppg-pft-dataset.html","title":"Soleimani's Dataset","lang":"zh-CN","frontmatter":{"title":"Soleimani's Dataset","icon":"database","timeline":true,"tag":["Dataset","Breath Tracking"],"description":"dPPG PFT 数据集详细介绍，含结构、评价指标、3D点云恢复方法。A comprehensive introduction to the dPPG PFT dataset, including structure, evaluation metrics, and 3D point cloud recovery.","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Soleimani's Dataset\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2026-01-07T06:21:45.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Dale\\",\\"url\\":\\"https://github.com/shyu216\\"}]}"],["meta",{"property":"og:url","content":"https://shyu216.github.io/knownoevil/knownoevil/study/mscs/research/cv/rrmonitor/dppg-pft-dataset.html"}],["meta",{"property":"og:site_name","content":"SIHONG's Blog"}],["meta",{"property":"og:title","content":"Soleimani's Dataset"}],["meta",{"property":"og:description","content":"dPPG PFT 数据集详细介绍，含结构、评价指标、3D点云恢复方法。A comprehensive introduction to the dPPG PFT dataset, including structure, evaluation metrics, and 3D point cloud recovery."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-07T06:21:45.000Z"}],["meta",{"property":"article:tag","content":"Breath Tracking"}],["meta",{"property":"article:tag","content":"Dataset"}],["meta",{"property":"article:modified_time","content":"2026-01-07T06:21:45.000Z"}]]},"git":{"createdTime":1747095371000,"updatedTime":1767766905000,"contributors":[{"name":"shyu216","username":"shyu216","email":"yusihong073@gmail.com","commits":4,"url":"https://github.com/shyu216"}]},"readingTime":{"minutes":2.39,"words":716},"filePathRelative":"study/mscs/research/cv/rrmonitor/dppg-pft-dataset.md","excerpt":"<p>以下内容由这个数据库的readme.txt文件翻译而来。</p>\\n<h2>简介</h2>\\n<p>dPPG PFT 数据集由布里斯托大学计算机科学系视觉信息实验室发布，包含 35 名受试者在进行用力肺活量（FVC）和缓慢肺活量（SVC）肺功能测试时的体表深度信息。数据集共计 300 个 PFT 序列，并包含每个序列的肺量计（spirometer）数据作为验证基准。</p>\\n<ul>\\n<li>适用于：深度视觉、呼吸监测、医学信号处理等研究</li>\\n<li>采集方式：双 Kinect 深度相机（前后各一），同步采集</li>\\n<li>公开时间：2018 年 2 月</li>\\n<li>主要联系人：<a href=\\"https://github.com/BristolVisualPFT\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Vahid Soleimani</a></li>\\n<li>数据集主页：<a href=\\"https://data.bris.ac.uk/data/dataset/1tqzx39mzkw832msuvy3obktqi\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">A Dataset for Depth-Based Whole Body Photoplethysmography in Remote Pulmonary Function Testing</a></li>\\n</ul>"}`);export{c as comp,d as data};
