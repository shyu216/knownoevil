import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as d,e as a,o as r}from"./app-D_B7y005.js";const o={};function c(n,t){return r(),d("div",null,[...t[0]||(t[0]=[a('<h3 id="what-is-this-course-about" tabindex="-1"><a class="header-anchor" href="#what-is-this-course-about"><span>What is this course about?</span></a></h3><p>前半部分是计算，后半是存储。怎么处理海量数据而不卡死，怎么保存海量数据而不撑爆。</p><h3 id="核心前提-mapreduce的核心分工" tabindex="-1"><a class="header-anchor" href="#核心前提-mapreduce的核心分工"><span>核心前提：MapReduce的核心分工</span></a></h3><p>先明确Map/Reduce的核心逻辑，所有分布式算法都是基于这个分工设计：</p><ul><li><strong>Map函数</strong>：「分片处理」—— 把大规模数据拆成小分片，每个分片独立计算局部结果（无数据依赖）；</li><li><strong>Reduce函数</strong>：「聚合归约」—— 把所有Map的局部结果汇总，计算全局最终结果；</li><li>迭代型算法（K-Means/PageRank）：多轮MapReduce循环，直到结果收敛（对应你代码里的<code>while run_next</code>）。</li></ul><hr><h3 id="经典算法的核心思路-map-reduce分工" tabindex="-1"><a class="header-anchor" href="#经典算法的核心思路-map-reduce分工"><span>经典算法的核心思路 + Map/Reduce分工</span></a></h3><h4 id="wordcount-with-counter-带计数器的词频统计" tabindex="-1"><a class="header-anchor" href="#wordcount-with-counter-带计数器的词频统计"><span>WordCount with Counter（带计数器的词频统计）</span></a></h4><h5 id="经典思路-核心" tabindex="-1"><a class="header-anchor" href="#经典思路-核心"><span>经典思路（核心）</span></a></h5><p>WordCount是MapReduce的入门核心场景：原本单机统计海量文本词频会因数据量过大卡死，核心是“分而治之”——先把文本拆分成单词，统计每个分片的局部词频，再汇总所有分片的结果得到全局词频；<br><strong>Counter（计数器）</strong> 是MapReduce的扩展能力：在统计词频的同时，用分布式计数器实时监控任务状态（如总单词数、空行数量、特殊字符数），无需额外遍历数据，提升任务可观测性。</p><h5 id="map-reduce分工" tabindex="-1"><a class="header-anchor" href="#map-reduce分工"><span>Map/Reduce分工</span></a></h5><table><thead><tr><th>阶段</th><th>Map函数做什么</th><th>Reduce函数做什么</th></tr></thead><tbody><tr><td>数据处理</td><td>1. 读取文本分片（按行读取），初始化3个Counter：<br> - <code>TOTAL_WORDS</code>（总单词数）<br> - <code>EMPTY_LINES</code>（空行数）<br> - <code>SPECIAL_CHARS</code>（特殊字符数）<br>2. 逐行处理：<br> - 若行为空，<code>EMPTY_LINES +=1</code>；<br> - 清洗行数据（去标点/转小写），拆分出单词；<br> - 每拆分一个单词，<code>TOTAL_WORDS +=1</code>；若单词含特殊字符，<code>SPECIAL_CHARS +=1</code>；<br>3. 输出局部词频：<code>单词\\t1</code></td><td>1. 输入：同一个单词的所有局部计数（如<code>hello\\t1</code>、<code>hello\\t1</code>）；<br>2. 聚合：累加同一个单词的计数（如<code>hello\\t2</code>）；<br>3. 输出全局词频：<code>单词\\t总次数</code>；<br>4. 无需额外操作Counter（Counter由MapReduce框架自动汇总所有Map节点的计数，任务结束后可直接查看）</td></tr><tr><td>结果输出</td><td>-</td><td>1. 输出最终的全局词频表；<br>2. MapReduce框架自动输出Counter汇总结果（如总单词数=100万、空行数=5000）</td></tr></tbody></table><h4 id="补充说明-counter的核心价值" tabindex="-1"><a class="header-anchor" href="#补充说明-counter的核心价值"><span>补充说明（Counter的核心价值）</span></a></h4><ul><li>Counter是MapReduce的<strong>分布式监控工具</strong>，无需在Map/Reduce中显式传递计数数据，框架会自动汇总所有节点的Counter值；</li><li>相比“额外统计计数再输出”，Counter更轻量（不占用Reduce的聚合资源），还能实时查看任务进度（比如跑任务时能看到“已统计10万单词”）。</li></ul><h4 id="并行dijkstra-单源最短路径" tabindex="-1"><a class="header-anchor" href="#并行dijkstra-单源最短路径"><span>并行Dijkstra（单源最短路径）</span></a></h4><h5 id="经典思路-核心-1" tabindex="-1"><a class="header-anchor" href="#经典思路-核心-1"><span>经典思路（核心）</span></a></h5><p>Dijkstra原本是单机算法：从起点出发，不断更新“起点到各节点的最短距离”，直到所有节点都被遍历。<br> 并行化核心：把节点/边分片，多节点同时计算局部最短路径，再汇总全局最短值，避免单机处理大规模图的性能瓶颈。</p><h5 id="map-reduce分工-1" tabindex="-1"><a class="header-anchor" href="#map-reduce分工-1"><span>Map/Reduce分工</span></a></h5><table><thead><tr><th>阶段</th><th>Map函数做什么</th><th>Reduce函数做什么</th></tr></thead><tbody><tr><td>初始化</td><td>读取图的边数据（格式：<code>起点\\t终点\\t边权重</code>），输出：<br>- 起点的已知最短距离（如起点A初始为0，其他为∞）<br>- 格式：<code>节点ID\\t(距离, 来源边)</code></td><td>无（第一轮仅初始化距离表）</td></tr><tr><td>迭代计算</td><td>输入：上一轮Reduce输出的「节点-最短距离」+ 原图边数据<br>对每条边（u→v，权重w），计算：<code>新距离 = u的已知距离 + w</code><br>输出：<code>v\\t新距离</code>（局部候选最短距离）</td><td>输入：同一个节点v的所有候选新距离<br>聚合：保留v的最小距离（全局最短）<br>输出：<code>v\\t全局最短距离</code></td></tr><tr><td>终止</td><td>当某轮Reduce输出的距离表无更新（收敛），停止迭代</td><td>-</td></tr></tbody></table><h4 id="pagerank-网页权重排名" tabindex="-1"><a class="header-anchor" href="#pagerank-网页权重排名"><span>PageRank（网页权重排名）</span></a></h4><h5 id="经典思路-核心-2" tabindex="-1"><a class="header-anchor" href="#经典思路-核心-2"><span>经典思路（核心）</span></a></h5><p>衡量网页重要性：一个网页的权重 = 所有指向它的网页的权重 / 指向网页的出度之和，加上阻尼系数（避免死链）。<br> 并行化核心：把网页链接关系分片，多节点同时计算局部网页的权重贡献，再汇总全局权重。</p><h5 id="map-reduce分工-2" tabindex="-1"><a class="header-anchor" href="#map-reduce分工-2"><span>Map/Reduce分工</span></a></h5><table><thead><tr><th>阶段</th><th>Map函数做什么</th><th>Reduce函数做什么</th></tr></thead><tbody><tr><td>初始化</td><td>读取网页链接数据（格式：<code>网页A\\t[网页B, 网页C]</code>），给每个网页初始化权重（如所有网页权重=1/N，N是总网页数）<br>输出：<code>网页ID\\t(权重, 出链列表)</code></td><td>无（第一轮初始化权重）</td></tr><tr><td>迭代计算</td><td>输入：上一轮Reduce输出的「网页-权重+出链」<br>对网页A（权重R，出链数k），给每个出链网页B分配权重：<code>R/k</code><br>输出：<br>- <code>网页B\\t分配的权重</code>（贡献值）<br>- <code>网页A\\t出链列表</code>（保留链接关系，供下一轮用）</td><td>输入：<br>1. 同一个网页的所有贡献值<br>2. 网页的出链列表<br>聚合计算：<br>新权重 = 阻尼系数*总贡献值 + (1-阻尼系数)/N<br>输出：<code>网页ID\\t(新权重, 出链列表)</code></td></tr><tr><td>终止</td><td>当某轮权重变化率&lt;阈值（收敛），停止迭代</td><td>-</td></tr></tbody></table><h4 id="k-means聚类-你的代码核心" tabindex="-1"><a class="header-anchor" href="#k-means聚类-你的代码核心"><span>K-Means聚类（你的代码核心）</span></a></h4><h5 id="经典思路-核心-3" tabindex="-1"><a class="header-anchor" href="#经典思路-核心-3"><span>经典思路（核心）</span></a></h5><p>K-Means原本是单机算法：随机选k个聚类中心 → 所有样本分配到最近的中心 → 重新计算每个类的中心 → 循环直到中心不变。<br> 并行化核心：把样本分片，多节点同时分配样本到中心，再汇总所有样本重新计算全局中心。</p><h5 id="map-reduce分工-3" tabindex="-1"><a class="header-anchor" href="#map-reduce分工-3"><span>Map/Reduce分工</span></a></h5><table><thead><tr><th>阶段</th><th>Map函数做什么</th><th>Reduce函数做什么</th></tr></thead><tbody><tr><td>初始化</td><td>读取样本数据，加载初始聚类中心（存储于HDFS上的文件）<br>此阶段不涉及Map/Reduce计算，仅将聚类中心文件分发到集群</td><td>-</td></tr><tr><td>迭代计算（Map）</td><td>输入：样本数据 + 聚类中心<br>对每个样本，计算到k个中心的距离，分配到最近的中心<br>输出：<code>中心ID\\t(样本特征, 1)</code>（1是样本计数）</td><td>输入：同一个中心ID的所有样本<br>聚合计算：<br>1. 汇总该类所有样本的特征之和<br>2. 统计该类样本总数<br>3. 计算新中心 = 特征之和 / 样本总数<br>输出：<code>中心ID\\t新中心坐标</code></td></tr><tr><td>收敛判断</td><td>对比本轮新中心和上一轮旧中心的距离（Norm值），若&lt;阈值则停止</td><td>-</td></tr></tbody></table><h3 id="补充说明" tabindex="-1"><a class="header-anchor" href="#补充说明"><span>补充说明</span></a></h3><p>在经典的MapReduce（如Hadoop）框架中，除了Mapper和Reducer，还有几个关键的“er”组件，它们共同协作完成分布式计算任务。下面是常见的几个：</p><table><thead><tr><th>组件</th><th>作用</th><th>出现阶段</th></tr></thead><tbody><tr><td><strong>Combiner</strong></td><td>本地聚合器，在Map端先对输出做一次合并（类似小型的Reduce），减少网络传输的数据量。</td><td>Map阶段之后，Shuffle之前</td></tr><tr><td><strong>Partitioner</strong></td><td>决定Map输出的每个键值对应该被发送到哪个Reducer（通过计算键的哈希值等）。</td><td>Map输出写入环形缓冲区时</td></tr><tr><td><strong>Shuffler</strong></td><td>不是独立组件，而是指Map输出传输到Reducer的过程，包括排序、合并、复制等。</td><td>Map和Reduce之间的数据传输阶段</td></tr><tr><td><strong>RecordReader</strong></td><td>将输入分片解析成键值对（如文本文件的一行作为一个值，偏移量作为键）。</td><td>Map任务读取输入数据时</td></tr><tr><td><strong>RecordWriter</strong></td><td>将Reduce输出的键值对写入最终文件（如文本文件、SequenceFile等）。</td><td>Reduce任务输出结果时</td></tr></tbody></table>',32)])])}const s=e(o,[["render",c]]),i=JSON.parse(`{"path":"/study/bscs/22T1/CSCI4180.html","title":"CSCI4180 Introduction to Cloud Computing and Storage","lang":"zh-CN","frontmatter":{"title":"CSCI4180 Introduction to Cloud Computing and Storage","shortTitle":"CSCI4180","icon":"book-open","order":7,"category":["CUHK","Course","22T1"],"tag":["Computer Science","Cloud Computing","Storage"],"description":"What is this course about? 前半部分是计算，后半是存储。怎么处理海量数据而不卡死，怎么保存海量数据而不撑爆。 核心前提：MapReduce的核心分工 先明确Map/Reduce的核心逻辑，所有分布式算法都是基于这个分工设计： Map函数：「分片处理」—— 把大规模数据拆成小分片，每个分片独立计算局部结果（无数据依赖）； Red...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"CSCI4180 Introduction to Cloud Computing and Storage\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2026-02-26T10:30:12.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Dale\\",\\"url\\":\\"https://github.com/shyu216\\"}]}"],["meta",{"property":"og:url","content":"https://shyu216.github.io/knownoevil/knownoevil/study/bscs/22T1/CSCI4180.html"}],["meta",{"property":"og:site_name","content":"SIHONG's Blog"}],["meta",{"property":"og:title","content":"CSCI4180 Introduction to Cloud Computing and Storage"}],["meta",{"property":"og:description","content":"What is this course about? 前半部分是计算，后半是存储。怎么处理海量数据而不卡死，怎么保存海量数据而不撑爆。 核心前提：MapReduce的核心分工 先明确Map/Reduce的核心逻辑，所有分布式算法都是基于这个分工设计： Map函数：「分片处理」—— 把大规模数据拆成小分片，每个分片独立计算局部结果（无数据依赖）； Red..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-02-26T10:30:12.000Z"}],["meta",{"property":"article:tag","content":"Storage"}],["meta",{"property":"article:tag","content":"Cloud Computing"}],["meta",{"property":"article:tag","content":"Computer Science"}],["meta",{"property":"article:modified_time","content":"2026-02-26T10:30:12.000Z"}]]},"git":{"createdTime":1746956306000,"updatedTime":1772101812000,"contributors":[{"name":"shyu216","username":"shyu216","email":"yusihong073@gmail.com","commits":4,"url":"https://github.com/shyu216"}]},"readingTime":{"minutes":6.43,"words":1930},"filePathRelative":"study/bscs/22T1/CSCI4180.md","excerpt":"<h3>What is this course about?</h3>\\n<p>前半部分是计算，后半是存储。怎么处理海量数据而不卡死，怎么保存海量数据而不撑爆。</p>\\n<h3>核心前提：MapReduce的核心分工</h3>\\n<p>先明确Map/Reduce的核心逻辑，所有分布式算法都是基于这个分工设计：</p>\\n<ul>\\n<li><strong>Map函数</strong>：「分片处理」—— 把大规模数据拆成小分片，每个分片独立计算局部结果（无数据依赖）；</li>\\n<li><strong>Reduce函数</strong>：「聚合归约」—— 把所有Map的局部结果汇总，计算全局最终结果；</li>\\n<li>迭代型算法（K-Means/PageRank）：多轮MapReduce循环，直到结果收敛（对应你代码里的<code>while run_next</code>）。</li>\\n</ul>","autoDesc":true}`);export{s as comp,i as data};
