import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,o as a,f as i}from"./app-C4722Gpd.js";const n={},r=i('<h2 id="_1-search" tabindex="-1"><a class="header-anchor" href="#_1-search"><span>1. Search</span></a></h2><ul><li>bfs</li><li>dfs</li><li>greedy best-first search</li><li>A* search</li><li>heuristic function</li></ul><h2 id="_3-markov-decision-process" tabindex="-1"><a class="header-anchor" href="#_3-markov-decision-process"><span>3. Markov Decision Process</span></a></h2><ul><li>state, action, transition probability, reward</li></ul><h2 id="_4-relaxation" tabindex="-1"><a class="header-anchor" href="#_4-relaxation"><span>4. Relaxation</span></a></h2><ul><li>add, delete, hmax, hadd, hff</li></ul><h2 id="_5-reinforcement-learning" tabindex="-1"><a class="header-anchor" href="#_5-reinforcement-learning"><span>5. Reinforcement Learning</span></a></h2><ul><li>value iteration, policy iteration</li><li>SARSA, Q-learning</li><li>monte carlo tree search, upper confidence bound</li><li>approximation</li><li>reward shaping</li></ul><h2 id="_6-game-theory" tabindex="-1"><a class="header-anchor" href="#_6-game-theory"><span>6. Game Theory</span></a></h2><ul><li>nash equilibrium</li></ul>',10),o=[r];function l(s,c){return a(),t("div",null,o)}const m=e(n,[["render",l],["__file","COMP90054.html.vue"]]),p=JSON.parse('{"path":"/master/COMP90054.html","title":"COMP90054 AI Planning for Autonomy","lang":"en-US","frontmatter":{"title":"COMP90054 AI Planning for Autonomy","shortTitle":"COMP90054","icon":"book-open","category":["UniMelb","24S1"],"tag":["Artificial Intelligence","Planning","Algorithm","Game Theory"],"description":"1. Search bfs dfs greedy best-first search A* search heuristic function 3. Markov Decision Process state, action, transition probability, reward 4. Relaxation add, delete, hmax,...","head":[["meta",{"property":"og:url","content":"https://shyu216.github.io/knownoevil/knownoevil/master/COMP90054.html"}],["meta",{"property":"og:site_name","content":"Know No Evil"}],["meta",{"property":"og:title","content":"COMP90054 AI Planning for Autonomy"}],["meta",{"property":"og:description","content":"1. Search bfs dfs greedy best-first search A* search heuristic function 3. Markov Decision Process state, action, transition probability, reward 4. Relaxation add, delete, hmax,..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-08-01T11:19:32.000Z"}],["meta",{"property":"article:author","content":"Dale"}],["meta",{"property":"article:tag","content":"Artificial Intelligence"}],["meta",{"property":"article:tag","content":"Planning"}],["meta",{"property":"article:tag","content":"Algorithm"}],["meta",{"property":"article:tag","content":"Game Theory"}],["meta",{"property":"article:modified_time","content":"2024-08-01T11:19:32.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"COMP90054 AI Planning for Autonomy\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-08-01T11:19:32.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Dale\\",\\"url\\":\\"https://github.com/shyu216\\"}]}"]]},"headers":[{"level":2,"title":"1. Search","slug":"_1-search","link":"#_1-search","children":[]},{"level":2,"title":"3. Markov Decision Process","slug":"_3-markov-decision-process","link":"#_3-markov-decision-process","children":[]},{"level":2,"title":"4. Relaxation","slug":"_4-relaxation","link":"#_4-relaxation","children":[]},{"level":2,"title":"5. Reinforcement Learning","slug":"_5-reinforcement-learning","link":"#_5-reinforcement-learning","children":[]},{"level":2,"title":"6. Game Theory","slug":"_6-game-theory","link":"#_6-game-theory","children":[]}],"git":{"createdTime":1722491295000,"updatedTime":1722511172000,"contributors":[{"name":"shyu216","email":"sihong1@student.unimelb.edu.au","commits":2}]},"readingTime":{"minutes":0.25,"words":74},"filePathRelative":"master/COMP90054.md","localizedDate":"August 1, 2024","autoDesc":true}');export{m as comp,p as data};
