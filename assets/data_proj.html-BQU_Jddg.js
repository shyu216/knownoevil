import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,a,d as e,o as r}from"./app-DtS26-rv.js";const l={};function i(d,t){return r(),o("div",null,[...t[0]||(t[0]=[a("p",null,[e("I learned some SQL at university, but I have never used PySpark."),a("br"),e(" I want to try modern data tools like Spark and big data platforms.")],-1),a("p",null,"Simple goals:",-1),a("ul",null,[a("li",null,"Install PySpark and run it on my laptop."),a("li",null,"Load a small dataset and query it with SQL."),a("li",null,"Compare SQL on a normal database and on Spark."),a("li",null,"Maybe build a tiny data pipeline or dashboard.")],-1),a("p",null,"I do not want a huge project. I just want to understand how PySpark feels in real work, and write down some notes about what is easy and what is painful.",-1)])])}const m=n(l,[["render",i]]),u=JSON.parse(`{"path":"/coding/ideas/data_proj.html","title":"Play with SQL and PySpark","lang":"zh-CN","frontmatter":{"title":"Play with SQL and PySpark","icon":"database","description":"I learned some SQL at university, but I have never used PySpark. I want to try modern data tools like Spark and big data platforms. Simple goals: Install PySpark and run it on m...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Play with SQL and PySpark\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2026-03-01T12:17:52.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Dale\\",\\"url\\":\\"https://github.com/shyu216\\"}]}"],["meta",{"property":"og:url","content":"https://shyu216.github.io/knownoevil/knownoevil/coding/ideas/data_proj.html"}],["meta",{"property":"og:site_name","content":"SIHONG's Blog"}],["meta",{"property":"og:title","content":"Play with SQL and PySpark"}],["meta",{"property":"og:description","content":"I learned some SQL at university, but I have never used PySpark. I want to try modern data tools like Spark and big data platforms. Simple goals: Install PySpark and run it on m..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-03-01T12:17:52.000Z"}],["meta",{"property":"article:modified_time","content":"2026-03-01T12:17:52.000Z"}]]},"git":{"createdTime":1772367472000,"updatedTime":1772367472000,"contributors":[{"name":"shyu216","username":"shyu216","email":"yusihong073@gmail.com","commits":1,"url":"https://github.com/shyu216"}]},"readingTime":{"minutes":0.33,"words":100},"filePathRelative":"coding/ideas/data_proj.md","excerpt":"<p>I learned some SQL at university, but I have never used PySpark.<br>\\nI want to try modern data tools like Spark and big data platforms.</p>\\n<p>Simple goals:</p>\\n<ul>\\n<li>Install PySpark and run it on my laptop.</li>\\n<li>Load a small dataset and query it with SQL.</li>\\n<li>Compare SQL on a normal database and on Spark.</li>\\n<li>Maybe build a tiny data pipeline or dashboard.</li>\\n</ul>","autoDesc":true}`);export{m as comp,u as data};
