import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,d as n,o}from"./app-Br3WD5P_.js";const t={};function l(r,e){return o(),i("div",null,e[0]||(e[0]=[n('<p>With the growing adoption of wearable and mobile devices, the use of AI in mobile health is becoming increasingly relevant for a variety of healthcare applications. However, deploying AI models on these resource-limited client devices poses significant challenges, restricting their applicability. This is especially the case with the introduction of large language models (LLMs) and multimodal LLMs, which require substantial memory and therefore present additional deployment hurdles.</p><p>Furthermore, safeguarding the privacy of sensitive client information necessitates local data processing. A promising approach is to design a collaborative learning framework that processes sensitive data locally while utilizing the cloud&#39;s extensive resources.</p><p>Additionally, client devices may only support limited modalities such as speech and images, while others might include additional sensor data like PPG and ECG. Thus, effectively harnessing comprehensive information through collaborative learning is also vital.</p><p>This project aims to develop a collaborative learning framework that enhances health inference and privacy and effectively leverages information across multiple modalities. By integrating both small and large language models on client devices and the cloud, this approach seeks to secure sensitive data and optimize the utilization of local and cloud resources for improved health outcomes.</p><p>Superivsor: <a href="https://tingdang90.github.io/" target="_blank" rel="noopener noreferrer">Ting Dang</a>, <a href="https://h-jia.github.io/" target="_blank" rel="noopener noreferrer">Hong Jia</a></p><h1 id="文献阅读" tabindex="-1"><a class="header-anchor" href="#文献阅读"><span>文献阅读</span></a></h1><h2 id="_1-lightllm-a-versatile-large-language-model-for-predictive-light-sensing" tabindex="-1"><a class="header-anchor" href="#_1-lightllm-a-versatile-large-language-model-for-predictive-light-sensing"><span>1. LightLLM: A Versatile Large Language Model for Predictive Light Sensing</span></a></h2><h3 id="有哪些光传感任务" tabindex="-1"><a class="header-anchor" href="#有哪些光传感任务"><span>有哪些光传感任务？</span></a></h3><p>indoor positioning, outdoor solar forecasting, and indoor solar estimation</p><h3 id="怎么处理数据" tabindex="-1"><a class="header-anchor" href="#怎么处理数据"><span>怎么处理数据？</span></a></h3><p>定位任务用graph neural network, forecasting任务用temporal convolutional network, estimation任务用cnn. LLM适合用说明性的knowledge graph和task-specific的prompt.</p><h3 id="怎么设置实验" tabindex="-1"><a class="header-anchor" href="#怎么设置实验"><span>怎么设置实验?</span></a></h3><p>找state-of-the-art, 针对任务找数据集, 消融实验, 可视化. LLM可以分析few-shot/zero-shot. 多找几个LLM. case study.</p><h2 id="_2-multimodal-large-language-models-in-human-centered-health-practical-insights" tabindex="-1"><a class="header-anchor" href="#_2-multimodal-large-language-models-in-human-centered-health-practical-insights"><span>2. Multimodal Large Language Models in Human-Centered Health: Practical Insights</span></a></h2><h3 id="多模态的三个方案" tabindex="-1"><a class="header-anchor" href="#多模态的三个方案"><span>多模态的三个方案?</span></a></h3><p>转化成文本, 用API, encoder+fine-tuning</p><h2 id="_3-lora-low-rank-adaptation-of-large-lan-guage-models" tabindex="-1"><a class="header-anchor" href="#_3-lora-low-rank-adaptation-of-large-lan-guage-models"><span>3. LORA: LOW-RANK ADAPTATION OF LARGE LAN-GUAGE MODELS</span></a></h2><h3 id="lora是什么" tabindex="-1"><a class="header-anchor" href="#lora是什么"><span>LoRA是什么?</span></a></h3><p>在transformer的每一层中注入可训练的低秩矩阵, 用于捕捉任务特定的特征. 这些矩阵的参数量远小于原始模型参数, 保持预训练模型的参数不变, 避免全参数微调的高成本.</p><h2 id="_4-human-centred-artificial-intelligence-for-mobile-health-sensing-challenges-and-opportunities" tabindex="-1"><a class="header-anchor" href="#_4-human-centred-artificial-intelligence-for-mobile-health-sensing-challenges-and-opportunities"><span>4. Human-centred artificial intelligence for mobile health sensing: challenges and opportunities</span></a></h2><h3 id="哪些传感器可以用于哪些领域" tabindex="-1"><a class="header-anchor" href="#哪些传感器可以用于哪些领域"><span>哪些传感器可以用于哪些领域?</span></a></h3><p>accelerometers, electrocardiograms (ECGs), global<br> positioning systems (GPSs), gyroscopes and microphones monitor our location, sleep, steps, eating and working habits in the real world.</p><p>数据包括audio, mobility, motion, biosignal, RF signal(射频信号, 蓝牙和wifi常用).</p><p>mobile health包括physical activity, disease diagnosis and mental health disorders.</p><h3 id="有哪些挑战" tabindex="-1"><a class="header-anchor" href="#有哪些挑战"><span>有哪些挑战?</span></a></h3><p>AI的interpretability, adaptability, privacy, robustness. wearable程度, methodology和evaluation.</p><h2 id="_5-efficient-and-personalized-mobile-health-event-prediction-via-small-language-models" tabindex="-1"><a class="header-anchor" href="#_5-efficient-and-personalized-mobile-health-event-prediction-via-small-language-models"><span>5. Efficient and Personalized Mobile Health Event Prediction via Small Language Models</span></a></h2><h3 id="slm怎么设置实验" tabindex="-1"><a class="header-anchor" href="#slm怎么设置实验"><span>SLM怎么设置实验?</span></a></h3><p>iphone+MobileAIBench. 没有baseline.</p><h2 id="_6-cloud-device-collaborative-learning-for-multimodal-large-language-models" tabindex="-1"><a class="header-anchor" href="#_6-cloud-device-collaborative-learning-for-multimodal-large-language-models"><span>6. Cloud-Device Collaborative Learning for Multimodal Large Language Models</span></a></h2><h3 id="它的解决方案" tabindex="-1"><a class="header-anchor" href="#它的解决方案"><span>它的解决方案?</span></a></h3><p>云上老师(大llama)和学生(小llama), 本地(device)学生上传少量token, 下载收到的参数.</p><h3 id="benchmark" tabindex="-1"><a class="header-anchor" href="#benchmark"><span>benchmark?</span></a></h3><p>VQA-v2, A-OKVQA, COCO Caption 2017 和 Nocaps.</p><h2 id="_7-mobile-edge-intelligence-for-large-language-models-a-contemporary-survey" tabindex="-1"><a class="header-anchor" href="#_7-mobile-edge-intelligence-for-large-language-models-a-contemporary-survey"><span>7. Mobile Edge Intelligence for Large Language Models: A Contemporary Survey</span></a></h2><h2 id="_8-on-device-language-models-a-comprehensive-review" tabindex="-1"><a class="header-anchor" href="#_8-on-device-language-models-a-comprehensive-review"><span>8. On-Device Language Models: A Comprehensive Review</span></a></h2>',36)]))}const d=a(t,[["render",l]]),c=JSON.parse(`{"path":"/research/candidate_topics/t-mh.html","title":"Cloud-Device Collaborative Learning via small and large lanauge models for mobile health","lang":"en-US","frontmatter":{"title":"Cloud-Device Collaborative Learning via small and large lanauge models for mobile health","shortTitle":"Mobile Health","order":1,"icon":"map-pin","category":["25S1"],"description":"With the growing adoption of wearable and mobile devices, the use of AI in mobile health is becoming increasingly relevant for a variety of healthcare applications. However, dep...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Cloud-Device Collaborative Learning via small and large lanauge models for mobile health\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-05-11T08:45:12.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Dale\\",\\"url\\":\\"https://github.com/shyu216\\"}]}"],["meta",{"property":"og:url","content":"https://shyu216.github.io/knownoevil/knownoevil/research/candidate_topics/t-mh.html"}],["meta",{"property":"og:site_name","content":"SIHONG's Blog"}],["meta",{"property":"og:title","content":"Cloud-Device Collaborative Learning via small and large lanauge models for mobile health"}],["meta",{"property":"og:description","content":"With the growing adoption of wearable and mobile devices, the use of AI in mobile health is becoming increasingly relevant for a variety of healthcare applications. However, dep..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-05-11T08:45:12.000Z"}],["meta",{"property":"article:modified_time","content":"2025-05-11T08:45:12.000Z"}]]},"git":{"createdTime":1739488850000,"updatedTime":1746953112000,"contributors":[{"name":"shyu216","username":"shyu216","email":"sihong1@student.unimelb.edu.au","commits":7,"url":"https://github.com/shyu216"}]},"filePathRelative":"research/candidate_topics/t-mh.md","excerpt":"<p>With the growing adoption of wearable and mobile devices, the use of AI in mobile health is becoming increasingly relevant for a variety of healthcare applications. However, deploying AI models on these resource-limited client devices poses significant challenges, restricting their applicability. This is especially the case with the introduction of large language models (LLMs) and multimodal LLMs, which require substantial memory and therefore present additional deployment hurdles.</p>","autoDesc":true}`);export{d as comp,c as data};
